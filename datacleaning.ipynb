{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import copy\n",
    "\n",
    "def debugger(key):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "        for a in dataset[key]:\n",
    "            print(f\"{a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headers setting\n",
    "colnames = [\"Tijdstempel\",\"programme\",\"mlcourse\",\"ircourse\",\"statcourse\",\"dbcourse\",\"gender\",\"chatGPT\",\"birthday\",\"studentestimate\",\n",
    "            \"stand\",\"stress\",\"sporthours\",\"random\",\"bedtime\",\"goodday1\",\"goodday2\"]\n",
    "dataset = pd.read_csv(\"./dataset/ODI-2024.csv\", skiprows=3, names=colnames)\n",
    "dataset.drop(\"Tijdstempel\", axis=1, inplace=True)\n",
    "dataset[\"mlcourse\"] = dataset[\"mlcourse\"].astype(\"category\")\n",
    "dataset[\"ircourse\"] = dataset[\"ircourse\"].astype(\"category\")\n",
    "dataset[\"statcourse\"] = dataset[\"statcourse\"].astype(\"category\")\n",
    "dataset[\"gender\"] = dataset[\"gender\"].astype(\"category\")\n",
    "dataset[\"chatGPT\"] = dataset[\"chatGPT\"].astype(\"category\")\n",
    "dataset[\"stand\"] = dataset[\"stand\"].astype(\"category\")\n",
    "#dataset.head()\n",
    "original_number=len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  0\n"
     ]
    }
   ],
   "source": [
    "#program generalize\n",
    "def generalizeProgramme(x):\n",
    "    if \"bioinformatics\" in x or \"bisb\" in x:\n",
    "        return \"bioinformatics and systems biology\"\n",
    "    if \"econometrics\" in x:\n",
    "        return \"econometrics and data science\"\n",
    "    if \"fintech\" in x:\n",
    "        return \"finiancial technology\"\n",
    "    if \"computational science\" in x:\n",
    "        return \"computational science\"\n",
    "    if \"human language technology\" in x:\n",
    "        return \"human language technology\"\n",
    "    if \"business analytics\" in x:\n",
    "        return \"business analytics\"\n",
    "    if \"computational finance\" in x:\n",
    "        return \"computational finance\"\n",
    "    if \"big data\" in x:\n",
    "        if \"engineering\" in x:\n",
    "            return \"big data engineering\"\n",
    "        else:\n",
    "            return \"big data\"\n",
    "    if \"political data journalism\" in x:\n",
    "        return \"political data journalism\"\n",
    "    if \"quantitative risk management\" in x:\n",
    "        return \"quantitative risk management\"\n",
    "    if \"software engineering\" in x:\n",
    "        return \"software engineering\"\n",
    "    if \"cls\" in x:\n",
    "        return \"critical language scholarship\"\n",
    "    if \" ai \" in x or \"artificial intelligence\" in x:\n",
    "        if \"health\" in x:\n",
    "            return \"ai for health\"\n",
    "        else:\n",
    "            return \"artificial intelligence\"\n",
    "    if \" cs \" in x or \"computer science\" in x:\n",
    "        return \"computer science\"\n",
    "    if \"ba\" in x:\n",
    "        return \"bachelor of arts\"\n",
    "    if \"mpa\" in x:\n",
    "        return \"public administration\"\n",
    "    \n",
    "\n",
    "dataset[\"programme\"] = dataset[\"programme\"].map(lambda x: x.lower())\n",
    "dataset[\"programme\"] = dataset[\"programme\"].map(lambda x: f\" {x} \")\n",
    "dataset[\"programme\"] = dataset[\"programme\"].map(generalizeProgramme)\n",
    "dataset['programme'] = dataset['programme'].fillna('unknown')\n",
    "dataset[\"programme\"] = dataset[\"programme\"].astype(\"category\")\n",
    "\n",
    "dataset.head()\n",
    "print(\"dropped: \",original_number-len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  0\n"
     ]
    }
   ],
   "source": [
    "#stress\n",
    "tmp = copy.deepcopy(dataset)\n",
    "def stress_outlier(dataset):\n",
    "    # Calculate the interquartile range (IQR)\n",
    "    Q1 = dataset['stress'].quantile(0.25)\n",
    "    Q3 = dataset['stress'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define the lower and upper bounds for outlier detection\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filter out the outliers\n",
    "    outliers = dataset[(dataset['stress'] < lower_bound) | (dataset['stress'] > upper_bound)]\n",
    "    \n",
    "    # Calculate the average stress level excluding the outliers\n",
    "    non_outlier_data = dataset[(dataset['stress'] >= lower_bound) & (dataset['stress'] <= upper_bound)]\n",
    "    avg_stress_without_outliers = non_outlier_data['stress'].mean()\n",
    "    \n",
    "    # Replace the outliers with the calculated average\n",
    "    dataset.loc[outliers.index, 'stress'] = avg_stress_without_outliers\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Apply the function to replace outliers with the average calculated without outliers\n",
    "dataset = stress_outlier(dataset)\n",
    "'''\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    for edited, original in zip(dataset['stress'], tmp['stress']):\n",
    "            print(f\"{original} => {edited}\")\n",
    "'''\n",
    "dataset.head()\n",
    "print(\"dropped: \",original_number-len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  2\n"
     ]
    }
   ],
   "source": [
    "#print(dataset.columns)\n",
    "#sporthours\n",
    "dataset['sporthours'] = dataset['sporthours'].astype(str).str.extract('(\\d+)').astype(float).fillna(0).astype(int)\n",
    "\n",
    "\n",
    "#student estimate\n",
    "dataset['studentestimate'] = pd.to_numeric(dataset['studentestimate'], errors='coerce').fillna(0)\n",
    "dataset['studentestimate'] = dataset['studentestimate'].apply(lambda x: round(x / 20) * 20)\n",
    "outlier_threshold = 600\n",
    "# Filter out row with 'studentestimate' values beyond the outlier threshold\n",
    "dataset = dataset[dataset['studentestimate'] <= outlier_threshold]\n",
    "dataset['random'] = pd.to_numeric(dataset['random'], errors='coerce').fillna(0)\n",
    "\n",
    "# ircourses\n",
    "dataset['ircourse'] = dataset['ircourse'].str.replace('0','no').str.replace('1','yes')\n",
    "\n",
    "\n",
    "# Estimate\n",
    "def clean_and_convert_estimate(value):\n",
    "    # Remove non-numeric characters and spaces\n",
    "    cleaned_value = re.sub(r'[^\\d-]+', '', str(value))\n",
    "    \n",
    "    # If the cleaned value contains a hyphen, split it into two numbers\n",
    "    if '-' in cleaned_value:\n",
    "        start, end = cleaned_value.split('-')\n",
    "        try:\n",
    "            return (int(start) + int(end)) // 2  # Return the average of the range\n",
    "        except ValueError:\n",
    "            return None  # Return None if the range cannot be converted\n",
    "    else:\n",
    "        # Convert to integer\n",
    "        try:\n",
    "            return int(cleaned_value)\n",
    "        except ValueError:\n",
    "            return None  # Return None if the value cannot be converted to an integer\n",
    "\n",
    "dataset['studentestimate'] = dataset['studentestimate'].map(clean_and_convert_estimate)\n",
    "#dataset.head()\n",
    "print(\"dropped: \",original_number-len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#comparing the pre elaboration with the post to check\\nwith pd.option_context(\\'display.max_rows\\', None, \\'display.max_columns\\', None): \\n    for edited, original in zip(dataset[\\'bedtime\\'], tmp[\\'bedtime\\']):\\n            print(f\"{original} => {edited}\")\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bedtime\n",
    "tmp= copy.deepcopy(dataset)#debug purpose\n",
    "\n",
    "def clean_time(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x = str(x)\n",
    "    patterns = [\n",
    "        r'(\\d{1,2}:\\d{2})',            # hh:mm format\n",
    "        r'(\\d{1,2}(\\.\\d{2})?\\s*[ap]m)', # hh[.mm] am/pm format\n",
    "        r'(\\d{1,2}\\s*(am|pm))',         # hh am/pm format\n",
    "        r'(\\d{1,2})'                    # hh format\n",
    "    ]\n",
    "    # Search for time value in the string using each pattern\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, x, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    #return np.nan\n",
    "    return \"00:00\"\n",
    "\n",
    "# Function to format time values as hh:mm\n",
    "def format_time(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    parts = x.split(':')\n",
    "    if len(parts) == 1:  # If only hour is provided\n",
    "        hour = parts[0].zfill(2)\n",
    "        return f\"{hour}:00\"\n",
    "    elif len(parts) == 2:  # If both hour and minute are provided\n",
    "        hour = parts[0].zfill(2)\n",
    "        minute = parts[1].zfill(2)\n",
    "        return f\"{hour}:{minute}\"\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "dataset['bedtime'] = dataset['bedtime'].astype(str).str.replace('AM', '').str.replace('PM', '').str.replace('s morgens', '').str.replace('am', '').str.replace('pm', '')\n",
    "dataset['bedtime'] = dataset['bedtime'].apply(clean_time)\n",
    "dataset['bedtime'] = dataset['bedtime'].apply(format_time)\n",
    "print(\"dropped: \",original_number-len(dataset))\n",
    "\n",
    "'''\n",
    "#comparing the pre elaboration with the post to check\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    for edited, original in zip(dataset['bedtime'], tmp['bedtime']):\n",
    "            print(f\"{original} => {edited}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 3 3\n",
      "10 1 10\n",
      "04 0 4\n",
      "10 1 10\n",
      "06 0 6\n",
      "05 0 5\n",
      "07 0 7\n",
      "12 1 12\n",
      "08 0 8\n",
      "05 0 5\n",
      "06 0 6\n",
      "10 1 10\n",
      "03 0 3\n",
      "09 0 9\n",
      "06 0 6\n",
      "11 1 11\n",
      "11 1 11\n",
      "10 1 10\n",
      "07 0 7\n",
      "08 0 8\n",
      "08 0 8\n",
      "08 0 8\n",
      "09 0 9\n",
      "08 0 8\n",
      "12 1 12\n",
      "03 0 3\n",
      "02 0 2\n",
      "09 0 9\n",
      "03 0 3\n",
      "9 9 9\n",
      "10 1 10\n",
      "08 0 8\n",
      "03 0 3\n",
      "1 1 1\n",
      "04 0 4\n",
      "05 0 5\n",
      "09 0 9\n",
      "03 0 3\n",
      "11 1 11\n",
      "01 0 1\n",
      "10 1 10\n",
      "01 0 1\n",
      "2 2 2\n",
      "08 0 8\n",
      "03 0 3\n",
      "01 0 1\n",
      "02 0 2\n",
      "11 1 11\n",
      "09 0 9\n",
      "5 5 5\n",
      "06 0 6\n",
      "10 1 10\n",
      "8 8 8\n",
      "02 0 2\n",
      "05 0 5\n",
      "09 0 9\n",
      "10 1 10\n",
      "10 1 10\n",
      "02 0 2\n",
      "5 5 5\n",
      "05 0 5\n",
      "2 2 2\n",
      "03 0 3\n",
      "10 1 10\n",
      "12 1 12\n",
      "11 1 11\n",
      "12 1 12\n",
      "10 1 10\n",
      "04 0 4\n",
      "05 0 5\n",
      "01 0 1\n",
      "09 0 9\n",
      "11 1 11\n",
      "09 0 9\n",
      "02 0 2\n",
      "02 0 2\n",
      "08 0 8\n",
      "10 1 10\n",
      "05 0 5\n",
      "09 0 9\n",
      "01 0 1\n",
      "03 0 3\n",
      "2 2 2\n",
      "03 0 3\n",
      "04 0 4\n",
      "07 0 7\n",
      "04 0 4\n",
      "04 0 4\n",
      "12 1 12\n",
      "07 0 7\n",
      "11 1 11\n",
      "12 1 12\n",
      "01 0 1\n",
      "01 0 1\n",
      "06 0 6\n",
      "03 0 3\n",
      "12 1 12\n",
      "07 0 7\n",
      "09 0 9\n",
      "05 0 5\n",
      "12 1 12\n",
      "08 0 8\n",
      "07 0 7\n",
      "04 0 4\n",
      "11 1 11\n",
      "06 0 6\n",
      "06 0 6\n",
      "03 0 3\n",
      "05 0 5\n",
      "7 7 7\n",
      "05 0 5\n",
      "03 0 3\n",
      "11 1 11\n",
      "01 0 1\n",
      "03 0 3\n",
      "03 0 3\n",
      "06 0 6\n",
      "06 0 6\n",
      "03 0 3\n",
      "07 0 7\n",
      "05 0 5\n",
      "4 4 4\n",
      "07 0 7\n",
      "11 1 11\n",
      "10 1 10\n",
      "08 0 8\n",
      "12 1 12\n",
      "05 0 5\n",
      "4 4 4\n",
      "04 0 4\n",
      "08 0 8\n",
      "06 0 6\n",
      "12 1 12\n",
      "02 0 2\n",
      "11 1 11\n",
      "09 0 9\n",
      "11 1 11\n",
      "08 0 8\n",
      "11 1 11\n",
      "11 1 11\n",
      "06 0 6\n",
      "11 1 11\n",
      "03 0 3\n",
      "11 1 11\n",
      "11 1 11\n",
      "05 0 5\n",
      "10 1 10\n",
      "08 0 8\n",
      "07 0 7\n",
      "06 0 6\n",
      "04 0 4\n",
      "11 1 11\n",
      "10 1 10\n",
      "10 1 10\n",
      "1 1 1\n",
      "06 0 6\n",
      "03 0 3\n",
      "01 0 1\n",
      "07 0 7\n",
      "11 1 11\n",
      "3 3 3\n",
      "01 0 1\n",
      "8 8 8\n",
      "04 0 4\n",
      "08 0 8\n",
      "11 1 11\n",
      "10 1 10\n",
      "9 9 9\n",
      "11 1 11\n",
      "06 0 6\n",
      "04 0 4\n",
      "04 0 4\n",
      "09 0 9\n",
      "05 0 5\n",
      "05 0 5\n",
      "11 1 11\n",
      "4 4 4\n",
      "12 1 12\n",
      "07 0 7\n",
      "12 1 12\n",
      "02 0 2\n",
      "04 0 4\n",
      "07 0 7\n",
      "05 0 5\n",
      "01 0 1\n",
      "03 0 3\n",
      "09 0 9\n",
      "12 1 12\n",
      "06 0 6\n",
      "8 8 8\n",
      "6 6 6\n",
      "03 0 3\n",
      "02 0 2\n",
      "06 0 6\n",
      "05 0 5\n",
      "08 0 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwith pd.option_context(\\'display.max_rows\\', None, \\'display.max_columns\\', None): \\n    for edited, original in zip(dataset[\\'bmonth\\'], tmp[\\'birthday\\']):\\n        if(str(edited) == \"nan\"):\\n            print(f\"{original} => {edited}\")\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#birthday\n",
    "def year(x):#losing 2 real years rows\n",
    "    patterns = [\n",
    "        r'((\\d{4,8}))',\n",
    "        r'\\b(\\d{4})\\b'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, x, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            val = str(match.group(1))\n",
    "            if len(val) > 4:\n",
    "                val = val[len(match.group(1))-4:]\n",
    "                \n",
    "            return val if int(val) >= 1980 and int(val) <= 2003 else np.nan\n",
    "        return np.nan\n",
    "    \n",
    "def month(x):#loses 3\n",
    "    x = str(x)\n",
    "    patterns = [\n",
    "        r'((\\d{6,8}))',\n",
    "        r'(\\d{1,4}[-,\\/,\\.,\\ ]\\d{1,2})'        \n",
    "    ]\n",
    "    # Search for time value in the string using each pattern\n",
    "    map = {\n",
    "        \"jan\": \"01\",    \"feb\": \"02\",    \"mar\": \"03\",\n",
    "        \"apr\": \"04\",    \"may\": \"05\",    \"jun\": \"06\",\n",
    "        \"jul\": \"07\",    \"aug\": \"08\",    \"sep\": \"09\",\n",
    "        \"oct\": \"10\",    \"nov\": \"11\",    \"dec\": \"12\"}\n",
    "\n",
    "    for y in map:\n",
    "        if y in x.lower():\n",
    "            return map[y]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, x, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            if(len(str(match.group(1))) !=8):\n",
    "                val=match.group(1)[len(match.group(1)) -2:].replace('/','').replace('.','').replace('-','')\n",
    "                val2=match.group(1)[:2].replace('/','').replace('.','').replace('-','')\n",
    "                final = str(val) if int(val)<=12 and int(val) >=1 else str(val2)\n",
    "            else:\n",
    "                val= match.group(1)[2:4]\n",
    "                val2= match.group(1)[0:2]\n",
    "                final = str(val) if int(val)<=12 and int(val) >=1 else str(val2)\n",
    "            #print(f\"{final} {final[0]} {final if final[0] != '0' else final[1:]}\")\n",
    "            return final if final[0] != '0' else final[1:]\n",
    "\n",
    "    return np.nan\n",
    "    \n",
    "dataset['byear'] = dataset['birthday'].apply(year)\n",
    "dataset['bmonth'] = dataset['birthday'].apply(month)\n",
    "'''\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    for edited, original in zip(dataset['bmonth'], tmp['birthday']):\n",
    "        if(str(edited) == \"nan\"):\n",
    "            print(f\"{original} => {edited}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('./dataset/normalized.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
