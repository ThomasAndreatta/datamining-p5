{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and data loading \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import re\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#headers setting\n",
    "colnames = [\"Tijdstempel\",\"programme\",\"mlcourse\",\"ircourse\",\"statcourse\",\"dbcourse\",\"gender\",\"chatGPT\",\"birthday\",\"studentestimate\",\n",
    "            \"stand\",\"stress\",\"sporthours\",\"random\",\"bedtime\",\"goodday1\",\"goodday2\"]\n",
    "dataset = pd.read_csv(\"./dataset/ODI-2024.csv\", skiprows=3, names=colnames)\n",
    "dataset.drop(\"Tijdstempel\", axis=1, inplace=True)\n",
    "dataset[\"mlcourse\"] = dataset[\"mlcourse\"].astype(\"category\")\n",
    "dataset[\"ircourse\"] = dataset[\"ircourse\"].astype(\"category\")\n",
    "dataset[\"statcourse\"] = dataset[\"statcourse\"].astype(\"category\")\n",
    "dataset[\"gender\"] = dataset[\"gender\"].astype(\"category\")\n",
    "dataset[\"chatGPT\"] = dataset[\"chatGPT\"].astype(\"category\")\n",
    "dataset[\"stand\"] = dataset[\"stand\"].astype(\"category\")\n",
    "backup = copy.deepcopy(dataset)\n",
    "\n",
    "def debugger(key,key2=None):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "        if key2:\n",
    "            for edited, original in zip(dataset[key], backup[key2]):\n",
    "                print(f\"{original} => {edited}\")\n",
    "        else:\n",
    "            for a in dataset[key]:\n",
    "                print(f\"{a}\")\n",
    "\n",
    "#dataset.head()\n",
    "original_number=len(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  0\n"
     ]
    }
   ],
   "source": [
    "#program generalize\n",
    "def generalizeProgramme(x):\n",
    "    if \"bioinformatics\" in x or \"bisb\" in x:\n",
    "        return \"bioinformatics and systems biology\"\n",
    "    if \"econometrics\" in x:\n",
    "        return \"econometrics and data science\"\n",
    "    if \"fintech\" in x:\n",
    "        return \"finiancial technology\"\n",
    "    if \"computational science\" in x:\n",
    "        return \"computational science\"\n",
    "    if \"human language technology\" in x:\n",
    "        return \"human language technology\"\n",
    "    if \"business analytics\" in x:\n",
    "        return \"business analytics\"\n",
    "    if \"computational finance\" in x:\n",
    "        return \"computational finance\"\n",
    "    if \"big data\" in x:\n",
    "        if \"engineering\" in x:\n",
    "            return \"big data engineering\"\n",
    "        else:\n",
    "            return \"big data\"\n",
    "    if \"political data journalism\" in x:\n",
    "        return \"political data journalism\"\n",
    "    if \"quantitative risk management\" in x:\n",
    "        return \"quantitative risk management\"\n",
    "    if \"software engineering\" in x:\n",
    "        return \"software engineering\"\n",
    "    if \"cls\" in x:\n",
    "        return \"critical language scholarship\"\n",
    "    if \" ai \" in x or \"artificial intelligence\" in x:\n",
    "        if \"health\" in x:\n",
    "            return \"ai for health\"\n",
    "        else:\n",
    "            return \"artificial intelligence\"\n",
    "    if \" cs \" in x or \"computer science\" in x:\n",
    "        return \"computer science\"\n",
    "    if \"ba\" in x:\n",
    "        return \"bachelor of arts\"\n",
    "    if \"mpa\" in x:\n",
    "        return \"public administration\"\n",
    "    \n",
    "\n",
    "dataset[\"programme\"] = dataset[\"programme\"].map(lambda x: x.lower())\n",
    "dataset[\"programme\"] = dataset[\"programme\"].map(lambda x: f\" {x} \")\n",
    "dataset[\"programme\"] = dataset[\"programme\"].map(generalizeProgramme)\n",
    "dataset['programme'] = dataset['programme'].fillna('unknown')\n",
    "dataset[\"programme\"] = dataset[\"programme\"].astype(\"category\")\n",
    "backup = copy.deepcopy(dataset)\n",
    "dataset.head()\n",
    "print(\"dropped: \",original_number-len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T21:51:02.840158Z",
     "start_time": "2024-04-07T21:51:02.835132Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  0\n"
     ]
    }
   ],
   "source": [
    "#stress\n",
    "tmp = copy.deepcopy(dataset)\n",
    "def stress_outlier(dataset):\n",
    "    # Calculate the interquartile range (IQR)\n",
    "    Q1 = dataset['stress'].quantile(0.25)\n",
    "    Q3 = dataset['stress'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define the lower and upper bounds for outlier detection\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Filter out the outliers\n",
    "    outliers = dataset[(dataset['stress'] < lower_bound) | (dataset['stress'] > upper_bound)]\n",
    "    \n",
    "    # Calculate the average stress level excluding the outliers\n",
    "    non_outlier_data = dataset[(dataset['stress'] >= lower_bound) & (dataset['stress'] <= upper_bound)]\n",
    "    avg_stress_without_outliers = non_outlier_data['stress'].mean()\n",
    "    \n",
    "    # Replace the outliers with the calculated average\n",
    "    dataset.loc[outliers.index, 'stress'] = avg_stress_without_outliers\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "def categorize_stress_level(stress):\n",
    "    if stress >=80:\n",
    "        return 'high'\n",
    "    elif stress >= 40:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'low'\n",
    "# Apply the function to replace outliers with the average calculated without outliers\n",
    "dataset = stress_outlier(dataset)\n",
    "dataset['stress_level'] = dataset['stress'].apply(categorize_stress_level)\n",
    "#debugger('stress','stress')\n",
    "\n",
    "print(\"dropped: \",original_number-len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4013209/16992405.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '6.6204081632653065' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  dataset.loc[dataset['z_score'].abs() > threshold, 'sporthours'] = max(mean - 1,0)\n"
     ]
    }
   ],
   "source": [
    "#print(dataset.columns)\n",
    "#sporthours\n",
    "dataset['sporthours'] = dataset['sporthours'].astype(str).str.extract('(\\d+)').astype(float).fillna(0).astype(int)\n",
    "#----\n",
    "# Calculate Z-score\n",
    "mean = dataset['sporthours'].mean()\n",
    "std = dataset['sporthours'].std()\n",
    "dataset['z_score'] = (dataset['sporthours'] - mean) / std\n",
    "\n",
    "# Replace extreme outliers with -1\n",
    "threshold = 3\n",
    "dataset.loc[dataset['z_score'].abs() > threshold, 'sporthours'] = max(mean - 1,0) \n",
    "\n",
    "# Drop the 'z_score' column if it's no longer needed\n",
    "dataset.drop(columns=['z_score'], inplace=True)\n",
    "#-----\n",
    "\n",
    "#student estimate\n",
    "dataset['studentestimate'] = pd.to_numeric(dataset['studentestimate'], errors='coerce').fillna(0)\n",
    "dataset['studentestimate'] = dataset['studentestimate'].apply(lambda x: round(x / 20) * 20)\n",
    "outlier_threshold = 600\n",
    "# Filter out row with 'studentestimate' values beyond the outlier threshold\n",
    "dataset = dataset[dataset['studentestimate'] <= outlier_threshold]\n",
    "dataset['random'] = pd.to_numeric(dataset['random'], errors='coerce').fillna(0)\n",
    "\n",
    "# ircourses\n",
    "dataset['ircourse'] = dataset['ircourse'].str.replace('0','no').str.replace('1','yes')\n",
    "\n",
    "\n",
    "# Estimate\n",
    "def clean_and_convert_estimate(value):\n",
    "    # Remove non-numeric characters and spaces\n",
    "    cleaned_value = re.sub(r'[^\\d-]+', '', str(value))\n",
    "    \n",
    "    # If the cleaned value contains a hyphen, split it into two numbers\n",
    "    if '-' in cleaned_value:\n",
    "        start, end = cleaned_value.split('-')\n",
    "        try:\n",
    "            return (int(start) + int(end)) // 2  # Return the average of the range\n",
    "        except ValueError:\n",
    "            return None  # Return None if the range cannot be converted\n",
    "    else:\n",
    "        # Convert to integer\n",
    "        try:\n",
    "            return int(cleaned_value)\n",
    "        except ValueError:\n",
    "            return None  # Return None if the value cannot be converted to an integer\n",
    "\n",
    "dataset['studentestimate'] = dataset['studentestimate'].map(clean_and_convert_estimate)\n",
    "#debugger('studentestimate','studentestimate')\n",
    "#dataset.head()\n",
    "print(\"dropped: \",original_number-len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped:  2\n"
     ]
    }
   ],
   "source": [
    "#bedtime\n",
    "\n",
    "def clean_time(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    x = str(x)\n",
    "    patterns = [\n",
    "        r'(\\d{1,2}:\\d{2})',            # hh:mm format\n",
    "        r'(\\d{1,2}(\\.\\d{2})?\\s*[ap]m)', # hh[.mm] am/pm format\n",
    "        r'(\\d{1,2}\\s*(am|pm))',         # hh am/pm format\n",
    "        r'(\\d{1,2})'                    # hh format\n",
    "    ]\n",
    "    # Search for time value in the string using each pattern\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, x, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            val = match.group(1).split(':')[0].replace('24','00')\n",
    "            val = val if val != '24' else '0'\n",
    "            #print(val, val == '24', val == 24)\n",
    "            return val\n",
    "    #return np.nan\n",
    "    return \"0\"\n",
    "\n",
    "# Function to format time values as hh:mm\n",
    "def format_time(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    parts = x.split(':')\n",
    "    if len(parts) == 1:  # If only hour is provided\n",
    "        hour = parts[0].zfill(2)\n",
    "        if (int(hour) >= 9) & (int(hour) <= 12): # If pm time is provided\n",
    "            hour = str(int(hour) + 12)\n",
    "        return f\"{hour}\"\n",
    "    elif len(parts) == 2:  # If both hour and minute are provided\n",
    "        hour = parts[0].zfill(2)\n",
    "        if (int(hour) >= 9) & (int(hour) <= 12): # If pm time is provided\n",
    "            hour = str(int(hour) + 12)\n",
    "        minute = parts[1].zfill(2)\n",
    "        return f\"{hour}\"\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "dataset['bedtime'] = dataset['bedtime'].astype(str).str.replace('AM', '').str.replace('PM', '').str.replace('s morgens', '').str.replace('am', '').str.replace('pm', '')\n",
    "dataset['bedtime'] = dataset['bedtime'].apply(clean_time)\n",
    "dataset['bedtime'] = dataset['bedtime'].apply(format_time)\n",
    "def format_time(time):\n",
    "    if '24' in time:\n",
    "        return time.replace('24', '00')\n",
    "    return time\n",
    "\n",
    "dataset['bedtime'] = dataset['bedtime'].apply(format_time)\n",
    "\n",
    "#debugger('bedtime','bedtime')\n",
    "print(\"dropped: \",original_number-len(dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4013209/2943817481.py:61: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  average_byear_by_programme = dataset.groupby('programme')['byear'].median().round().astype('Int64')\n"
     ]
    }
   ],
   "source": [
    "#birthday\n",
    "def year(x):#losing 2 real years rows\n",
    "    patterns = [\n",
    "        r'((\\d{4,8}))',\n",
    "        r'\\b(\\d{4})\\b'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, x, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            val = str(match.group(1))\n",
    "            if len(val) > 4:\n",
    "                val = val[len(match.group(1))-4:]\n",
    "            if 80 <= int(val[-2:]) <= 99:\n",
    "                val = '19' + val[-2:]\n",
    "                \n",
    "            return val if int(val) >= 1980 and int(val) <= 2003 else np.nan\n",
    "        return np.nan\n",
    "    \n",
    "def month(x):#loses 3\n",
    "    x = str(x)\n",
    "    patterns = [\n",
    "        r'((\\d{6,8}))',\n",
    "        r'(\\d{1,4}[-,\\/,\\.,\\ ]\\d{1,2})'        \n",
    "    ]\n",
    "    # Search for time value in the string using each pattern\n",
    "    map = {\n",
    "        \"jan\": \"01\",    \"feb\": \"02\",    \"mar\": \"03\",\n",
    "        \"apr\": \"04\",    \"may\": \"05\",    \"jun\": \"06\",\n",
    "        \"jul\": \"07\",    \"aug\": \"08\",    \"sep\": \"09\",\n",
    "        \"oct\": \"10\",    \"nov\": \"11\",    \"dec\": \"12\"}\n",
    "\n",
    "    for y in map:\n",
    "        if y in x.lower():\n",
    "            return map[y]\n",
    "\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, x, flags=re.IGNORECASE)\n",
    "        if match:\n",
    "            if(len(str(match.group(1))) !=8):\n",
    "                val=match.group(1)[len(match.group(1)) -2:].replace('/','').replace('.','').replace('-','')\n",
    "                val2=match.group(1)[:2].replace('/','').replace('.','').replace('-','')\n",
    "                final = str(val) if int(val)<=12 and int(val) >=1 else str(val2)\n",
    "            else:\n",
    "                val= match.group(1)[2:4]\n",
    "                val2= match.group(1)[0:2]\n",
    "                final = str(val) if int(val)<=12 and int(val) >=1 else str(val2)\n",
    "            #print(f\"{final} {final[0]} {final if final[0] != '0' else final[1:]}\")\n",
    "            return final if final[0] != '0' else final[1:]\n",
    "\n",
    "    return np.nan\n",
    "    \n",
    "dataset['byear'] = dataset['birthday'].apply(year)\n",
    "dataset['bmonth'] = dataset['birthday'].apply(month)\n",
    "\n",
    "\n",
    "#Byear data filling\n",
    "dataset['byear'] = pd.to_numeric(dataset['byear'], errors='coerce')\n",
    "\n",
    "# Calculate the average birth year for each programme and \n",
    "#Update missing 'byear' values based on the average birth year of students within the same 'programme'\n",
    "average_byear_by_programme = dataset.groupby('programme')['byear'].median().round().astype('Int64')\n",
    "for index, row in dataset.iterrows():\n",
    "    if pd.isna(row['byear']):\n",
    "        programme = row['programme']\n",
    "        avg_byear = average_byear_by_programme[programme]\n",
    "        dataset.at[index, 'byear'] = avg_byear\n",
    "\n",
    "#fill the only one without the byear with a plausible one and converts all of them to int\n",
    "dataset['byear'] = pd.to_numeric(dataset['byear'], errors='coerce').fillna(2000).astype(int)\n",
    "\n",
    "#debugger('byear','birthday')\n",
    "#debugger('bmonth','birthday')\n",
    "backup=copy.deepcopy(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('./dataset/normalized.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping them <into higher level product categories (e.g. a Pizza Margherita and Pizza Quattro Formaggi)> cit.\n",
    "With this code, we categorize\n",
    "1. \"sporthours\" (activity_intensity) feature into three levels of intensity: low, moderate, and high\n",
    "2. \"bedtime\" (bedtime_segment) feature into 6 levels Latenight, early morning, morning, afternoon, evening and night\n",
    "3. \"knowledge\" sums the values(positive/negative/unknown) of mlcourse, ircourse, statcourse, dbcourse\n",
    "4. \"mental_age\" based on the byear + stress + sportshours we find the \"mental\" age of a student. \"mental_biological_age\" have match,younger,older based on the biological age and mental age cause college kills your brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sport hours grouping\n",
    "def categorize_intensity(hours):\n",
    "    if hours < 3:\n",
    "        return 'low'\n",
    "    elif hours >= 3 and hours < 7:\n",
    "        return 'moderate'\n",
    "    else:\n",
    "        return 'high'\n",
    "dataset['activity_intensity'] = dataset['sporthours'].apply(categorize_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bedtime grouping\n",
    "def categorize_bedtime(bedtime):\n",
    "    hour = int(bedtime.split(':')[0])\n",
    "    if hour >= 23 or hour < 4:\n",
    "        return 'Late Night'\n",
    "    elif hour >= 4 and hour < 8:\n",
    "        return 'Early Morning'\n",
    "    elif hour >= 8 and hour < 12:\n",
    "        return 'Morning'\n",
    "    elif hour >= 12 and hour < 15:\n",
    "        return 'Afternoon'\n",
    "    elif hour >= 15 and hour < 20:\n",
    "        return 'Evening'\n",
    "    else:\n",
    "        return 'Night'\n",
    "dataset['bedtime_segment'] = dataset['bedtime'].apply(categorize_bedtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge in datamining helpfull courses\n",
    "def map_to_score(value):\n",
    "    multiplier = 2 #to increase the toatl difference for graphs purpose\n",
    "    if value == 'yes' or value == 'mu' or value == 'mu':\n",
    "        return 2 * multiplier\n",
    "    elif value == 'no' or value == 'sigma':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 * multiplier\n",
    "\n",
    "# Sum up the scores from the columns\n",
    "dataset['knowledge'] = dataset[['mlcourse', 'ircourse', 'statcourse', 'dbcourse']].apply(lambda row: sum(map(map_to_score, row)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'match': 28\n",
      "Number of 'younger': 33\n",
      "Number of 'older': 182\n",
      "University (*masters*) shortens your life, we knew that.\n"
     ]
    }
   ],
   "source": [
    "#byear + stress + sportshours to find the \"mental\" age of a student\n",
    "#mental_age = (age + stress/10) - sporthours/5\n",
    "current_year = pd.Timestamp.now().year\n",
    "dataset['age'] = (current_year-dataset['byear'])\n",
    "dataset['mental_age'] = (current_year-dataset['byear']) + (dataset['stress'] / 10) - (dataset['sporthours'] / 5)\n",
    "dataset['mental_age'] = dataset['mental_age'].round().astype(int)\n",
    "\n",
    "# Create the 'mental_biological_age' column based on the relationship between 'age' and 'mental_age'\n",
    "def determine_mental_biological_age(row):\n",
    "    if row['age'] == row['mental_age']:\n",
    "        return 'match'\n",
    "    elif row['age'] > row['mental_age']:\n",
    "        return 'younger'\n",
    "    else:\n",
    "        return 'older'\n",
    "\n",
    "dataset['mental_biological_age'] = dataset.apply(determine_mental_biological_age, axis=1)\n",
    "age_counts = dataset['mental_biological_age'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Number of 'match':\", age_counts.get('match', 0))\n",
    "print(\"Number of 'younger':\", age_counts.get('younger', 0))\n",
    "print(\"Number of 'older':\", age_counts.get('older', 0))\n",
    "print(\"University (*masters*) shortens your life, we knew that.\")\n",
    "\n",
    "#debugger('mental_biological_age','byear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset columns dropping and reordering\n",
    "dataset.drop(columns=['goodday1', 'goodday2','birthday','stand','studentestimate' ], inplace=True)\n",
    "desired_columns = ['programme', 'mlcourse', 'ircourse', 'statcourse', 'dbcourse', 'knowledge', 'stress','stress_level' ,'bedtime', 'bedtime_segment', 'sporthours', 'activity_intensity', 'byear', 'age', 'mental_age', 'mental_biological_age', 'gender', 'chatGPT', 'random', 'bmonth']\n",
    "\n",
    "# Reindex the DataFrame with the desired column order\n",
    "dataset = dataset.reindex(columns=desired_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('./dataset/feature_engineering.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Training set and testing set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset saved as 'train_dataset.csv'\n",
      "Test dataset saved as 'test_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Save the training and testing datasets to separate CSV files\n",
    "train_data.to_csv('./dataset/train_dataset.csv', index=False)\n",
    "test_data.to_csv('./dataset/test_dataset.csv', index=False)\n",
    "\n",
    "print(\"Train dataset saved as 'train_dataset.csv'\")\n",
    "print(\"Test dataset saved as 'test_dataset.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
